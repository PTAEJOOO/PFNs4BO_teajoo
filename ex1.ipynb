{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nn.Linear(50,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "decoder_input = torch.rand(32,100,50)\n",
    "decoder_output = decoder(decoder_input)\n",
    "print(decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2922, -0.2054, -0.3956, -0.3311,  0.0612,  0.4051, -0.2804, -0.1187,\n",
      "        -0.3056, -0.3681,  0.3640,  0.3437,  0.2199, -0.1579,  0.1786,  0.1638,\n",
      "         0.0344,  0.0934,  0.0931, -0.4408, -0.8414,  0.0593,  0.2242,  0.1501,\n",
      "        -0.4293,  0.0312, -0.2293, -0.3472, -0.1272, -0.2919,  0.5080,  0.1690,\n",
      "         0.4366,  0.4158, -0.0054,  0.2943, -0.5481, -0.0244, -0.1767,  0.1667,\n",
      "         0.3313,  0.3906, -0.4446,  0.5121, -0.1443,  0.0738, -0.1822, -0.0846,\n",
      "        -0.7640, -0.4090,  0.3801, -1.0907, -0.0948,  0.1942, -0.2738, -0.2938,\n",
      "         0.0042, -0.0948, -0.2106, -0.3535,  0.1637, -0.0181, -0.3271,  0.0500,\n",
      "         0.4417,  0.0418,  0.2129,  0.1864,  0.1630, -0.5445, -0.1679,  0.0298,\n",
      "         0.2825, -0.8279,  0.4854, -1.0426,  0.2697, -0.2426,  0.7397, -0.1191,\n",
      "        -0.0151, -0.1437,  0.5148,  0.3006,  0.0264,  0.1464, -0.4273, -0.1789,\n",
      "        -0.4207, -0.2534,  0.6260, -0.1082, -0.3113, -0.0452,  0.0843, -0.4715,\n",
      "        -0.4042, -0.1171, -0.1131,  0.3249], grad_fn=<SelectBackward0>)\n",
      "torch.Size([3200, 100])\n"
     ]
    }
   ],
   "source": [
    "loss_input = decoder_output.reshape(-1, 100)\n",
    "print(loss_input[0])\n",
    "print(loss_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_limits(num_outputs:int, full_range:tuple=None, ys:torch.Tensor=None):\n",
    "    assert (ys is not None) or (full_range is not None)\n",
    "    if ys is not None:\n",
    "        ys = ys.flatten()\n",
    "        if len(ys) % num_outputs: ys = ys[:-(len(ys) % num_outputs)]\n",
    "        print(f'Using {len(ys)} y evals to estimate {num_outputs} buckets. Cut off the last {len(ys) % num_outputs} ys.')\n",
    "        ys_per_bucket = len(ys) // num_outputs\n",
    "        if full_range is None:\n",
    "            full_range = (ys.min(), ys.max())\n",
    "        else:\n",
    "            assert full_range[0] <= ys.min() and full_range[1] >= ys.max()\n",
    "            full_range = torch.tensor(full_range)\n",
    "        ys_sorted, ys_order = ys.sort(0)\n",
    "        bucket_limits = (ys_sorted[ys_per_bucket-1::ys_per_bucket][:-1]+ys_sorted[ys_per_bucket::ys_per_bucket])/2\n",
    "        print(full_range)\n",
    "        bucket_limits = torch.cat([full_range[0].unsqueeze(0), bucket_limits, full_range[1].unsqueeze(0)],0)\n",
    "\n",
    "    else:\n",
    "        class_width = (full_range[1] - full_range[0]) / num_outputs\n",
    "        bucket_limits = torch.cat([full_range[0] + torch.arange(num_outputs).float()*class_width, torch.tensor(full_range[1]).unsqueeze(0)], 0)\n",
    "\n",
    "    assert len(bucket_limits) - 1 == num_outputs and full_range[0] == bucket_limits[0] and full_range[-1] == bucket_limits[-1]\n",
    "    return bucket_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.0000, -4.9000, -4.8000, -4.7000, -4.6000, -4.5000, -4.4000, -4.3000,\n",
      "        -4.2000, -4.1000, -4.0000, -3.9000, -3.8000, -3.7000, -3.6000, -3.5000,\n",
      "        -3.4000, -3.3000, -3.2000, -3.1000, -3.0000, -2.9000, -2.8000, -2.7000,\n",
      "        -2.6000, -2.5000, -2.4000, -2.3000, -2.2000, -2.1000, -2.0000, -1.9000,\n",
      "        -1.8000, -1.7000, -1.6000, -1.5000, -1.4000, -1.3000, -1.2000, -1.1000,\n",
      "        -1.0000, -0.9000, -0.8000, -0.7000, -0.6000, -0.5000, -0.4000, -0.3000,\n",
      "        -0.2000, -0.1000,  0.0000,  0.1000,  0.2000,  0.3000,  0.4000,  0.5000,\n",
      "         0.6000,  0.7000,  0.8000,  0.9000,  1.0000,  1.1000,  1.2000,  1.3000,\n",
      "         1.4000,  1.5000,  1.6000,  1.7000,  1.8000,  1.9000,  2.0000,  2.1000,\n",
      "         2.2000,  2.3000,  2.4000,  2.5000,  2.6000,  2.7000,  2.8000,  2.9000,\n",
      "         3.0000,  3.1000,  3.2000,  3.3000,  3.4000,  3.5000,  3.6000,  3.7000,\n",
      "         3.8000,  3.9000,  4.0000,  4.1000,  4.2000,  4.3000,  4.4000,  4.5000,\n",
      "         4.6000,  4.7000,  4.8000,  4.9000,  5.0000])\n"
     ]
    }
   ],
   "source": [
    "borders=get_bucket_limits(100, full_range=(-5,5))\n",
    "print(borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.9032, -4.8164, -5.0066, -4.9421, -4.5498, -4.2059, -4.8914, -4.7297,\n",
      "        -4.9166, -4.9791, -4.2470, -4.2673, -4.3911, -4.7689, -4.4324, -4.4472,\n",
      "        -4.5766, -4.5176, -4.5179, -5.0518, -5.4524, -4.5517, -4.3868, -4.4609,\n",
      "        -5.0403, -4.5798, -4.8403, -4.9582, -4.7382, -4.9029, -4.1030, -4.4420,\n",
      "        -4.1745, -4.1952, -4.6164, -4.3168, -5.1591, -4.6354, -4.7877, -4.4443,\n",
      "        -4.2797, -4.2205, -5.0556, -4.0989, -4.7553, -4.5372, -4.7932, -4.6956,\n",
      "        -5.3750, -5.0201, -4.2309, -5.7017, -4.7058, -4.4168, -4.8848, -4.9048,\n",
      "        -4.6068, -4.7058, -4.8216, -4.9645, -4.4473, -4.6291, -4.9382, -4.5610,\n",
      "        -4.1693, -4.5692, -4.3981, -4.4246, -4.4480, -5.1555, -4.7789, -4.5812,\n",
      "        -4.3285, -5.4389, -4.1256, -5.6536, -4.3413, -4.8536, -3.8713, -4.7301,\n",
      "        -4.6261, -4.7547, -4.0962, -4.3104, -4.5846, -4.4646, -5.0383, -4.7899,\n",
      "        -5.0318, -4.8644, -3.9850, -4.7192, -4.9224, -4.6562, -4.5268, -5.0825,\n",
      "        -5.0152, -4.7281, -4.7241, -4.2861], grad_fn=<SelectBackward0>)\n",
      "torch.Size([3200, 100])\n",
      "tensor([-2.6006, -2.5139, -2.7041, -2.6395, -2.2472, -1.9033, -2.5888, -2.4271,\n",
      "        -2.6140, -2.6766, -1.9444, -1.9647, -2.0885, -2.4663, -2.1298, -2.1446,\n",
      "        -2.2740, -2.2150, -2.2153, -2.7492, -3.1498, -2.2492, -2.0842, -2.1583,\n",
      "        -2.7377, -2.2772, -2.5377, -2.6556, -2.4356, -2.6003, -1.8004, -2.1394,\n",
      "        -1.8719, -1.8926, -2.3138, -2.0142, -2.8565, -2.3328, -2.4852, -2.1417,\n",
      "        -1.9771, -1.9179, -2.7531, -1.7964, -2.4527, -2.2346, -2.4906, -2.3930,\n",
      "        -3.0724, -2.7175, -1.9283, -3.3991, -2.4032, -2.1143, -2.5823, -2.6022,\n",
      "        -2.3042, -2.4032, -2.5190, -2.6619, -2.1448, -2.3265, -2.6356, -2.2584,\n",
      "        -1.8668, -2.2667, -2.0955, -2.1221, -2.1454, -2.8529, -2.4763, -2.2786,\n",
      "        -2.0259, -3.1363, -1.8230, -3.3510, -2.0387, -2.5510, -1.5687, -2.4275,\n",
      "        -2.3236, -2.4521, -1.7937, -2.0078, -2.2820, -2.1620, -2.7357, -2.4873,\n",
      "        -2.7292, -2.5618, -1.6824, -2.4166, -2.6198, -2.3536, -2.2242, -2.7800,\n",
      "        -2.7126, -2.4255, -2.4216, -1.9835], grad_fn=<SelectBackward0>)\n",
      "torch.Size([3200, 100])\n"
     ]
    }
   ],
   "source": [
    "bucket_log_probs = torch.log_softmax(loss_input, -1)\n",
    "print(bucket_log_probs[0])\n",
    "print(bucket_log_probs.shape)\n",
    "\n",
    "bucket_widths = borders[1:] - borders[:-1]\n",
    "scaled_bucket_log_probs = bucket_log_probs - torch.log(bucket_widths)\n",
    "print(scaled_bucket_log_probs[0])\n",
    "print(scaled_bucket_log_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_bucket_idx(borders, y):\n",
    "    target_sample = torch.searchsorted(borders, y) - 1\n",
    "    target_sample[y == borders[0]] = 0\n",
    "    target_sample[y == borders[-1]] = 100 - 1\n",
    "    return target_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1873, 0.5338, 0.9764,  ..., 0.9534, 0.5121, 0.1801])\n",
      "torch.Size([3200])\n",
      "tensor([51, 55, 59,  ..., 59, 55, 51])\n",
      "torch.Size([3200])\n",
      "torch.Size([3200, 1])\n",
      "tensor(51)\n",
      "tensor(3.3991, grad_fn=<NegBackward0>)\n",
      "tensor(55)\n",
      "tensor(2.9402, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 위의 input x=[3200, 100] 에 대응하는 y=[3200]\n",
    "targets = torch.rand(32,100,1).flatten()\n",
    "print(targets)\n",
    "print(targets.shape)\n",
    "target_sample = map_to_bucket_idx(borders, targets)\n",
    "print(target_sample)\n",
    "print(target_sample.shape)\n",
    "print(target_sample.unsqueeze(-1).shape)\n",
    "print(target_sample[0])\n",
    "print(-scaled_bucket_log_probs[0,target_sample[0]])\n",
    "print(target_sample[-2])\n",
    "print(-scaled_bucket_log_probs[-2,target_sample[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.3991, 2.8007, 2.6417,  ..., 2.6891, 2.9402, 2.9419],\n",
      "       grad_fn=<NegBackward0>)\n",
      "torch.Size([3200])\n"
     ]
    }
   ],
   "source": [
    "losses = -scaled_bucket_log_probs.gather(-1,target_sample.unsqueeze(-1)).squeeze(-1)\n",
    "print(losses)\n",
    "print(losses.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.3991, 2.8007, 2.6417,  ..., 2.0208, 2.2635, 2.8726],\n",
      "        [2.6442, 2.4853, 3.0302,  ..., 2.1433, 2.3291, 2.4181],\n",
      "        [2.0150, 2.5583, 2.8525,  ..., 2.4902, 2.3388, 2.8720],\n",
      "        ...,\n",
      "        [1.9488, 2.7554, 2.6354,  ..., 2.3348, 1.9084, 2.2315],\n",
      "        [2.4966, 2.2723, 2.2883,  ..., 2.9811, 2.6794, 2.6002],\n",
      "        [2.2101, 2.2639, 2.5728,  ..., 2.6891, 2.9402, 2.9419]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([32, 100])\n",
      "tensor(2.5179, grad_fn=<MeanBackward0>)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "losses = losses.view(*decoder_output.shape[0:2]).squeeze(-1)\n",
    "print(losses)\n",
    "print(losses.shape)\n",
    "loss = losses.mean()\n",
    "print(loss)\n",
    "print(loss.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_pfns4bo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
